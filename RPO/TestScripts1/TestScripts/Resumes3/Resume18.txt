Sarat Ku. Sethy	-ETL/Bigdata Test Lead
Pan:- FGHJU1236J, PassPort:- J1236541, Gender:- Msle, Dob:- 16/07/1985			   
Professional Summary: 

Having 9  experience  in Big data testing, ETL/DWH Testing & BI Reports Testing in Banking , Insurance, Healthcare  and finance domain 
Having 5 years of testing experience on IBM BDW and IBM IIW Data Model.
Having 3 years of working experience on Big data testing using Selenium, Python selenium web driver, NoSQL database, Hive and Apache Spark, Hadoop cluster in Cloud environment 
Having overall experience in writing automated test script using SQL & NoSQL in various databases such as DB2, Teradata and MS SQL Server as well as MongoDB, Hbase.
Experienced in analyzing Business Requirements and Specifications. Worked with Development team and Business Analysts to analyze the test data, test scenarios and ensure that test requirements are correct and complete.
Expertise   in preparing Test Plan , Testing strategy and Testing Approach  for any kind of ETL end to end application (Data Mart and Data ware house as well as Reporting Projects) in banking and Insurance domain.
Experience in preparing SQL automated test framework based on the ETL mapping and design documents.
Actively involved in User Acceptance Testing (UAT) and Training of the end users. Participated in cross-functional teams to reengineer and improve business processes.
Extensive experience in reviewing Business Requirement Documents, Software Requirement Documents and preparing Test Plan ,Test Cases ,Test scripts and Execution
Proficiency in Test Analysis, Bug Detection, Defect isolation and report generation skill as well as designing and executing Test cases.
Good experience in defect tracking and reporting using HP ALM and QC.
Proficient in Network and security protocol.
Experience in Analytic language such as PIG, HIVE as well as NoSQL database. 
Good experience in Python, Machine Language and Markup chain.
Good experience in Predictive analysis using Spot fire and R.
 Excellent at analyzing product requirements, functional design developing and executing test Plan.  
Ability to learn quickly and to correctly apply new tools and technology.
Good communication skills, interpersonal skills, self-motivated, quick learner, team player.
Good Experience in JIRA, Agile and scrum methodology.

Skill Set
RDBMS			: Oracle 8.1, MS-SQL Server 6.5/7.0, Teradata, DB2, Netezza
ETL tool 			:  DataStage, Informatica, 
Scripting Language 	 	:  Shell Script, Perl scripts, Python
O/S			:  Unix and Windows
Bigdata Processing engine	:  Hadoop, Apache Spark.
NoSQL Database		:  MongoDB, Hbase.
Analtyics SQL			:   Hive,PIG
Cloud 			:  Amazon Cloud Service(AWS)
Defect Tracking Tool	                : HP Mercury QC 8.2, HP ALM



Education:  	
B.E in Computer Science  from Utkal University


Professional Experience

Nov 2015 - Till date Big data Research & innovation Test Lead Honeywell Solution Lab

 1.Doing testing on smart diagnosis of retail scanner and industrial printer.
2. Doing real time analysis as well as predictive analysis of hardware products such as scanner, mobile and printer logs .		
3. Real time Data Analysis app for voice based scanner.  

 Nov 2009 – Nov 2015,	ETL & BI Test Lead           	IBM India Pvt. Ltd. 

1) PROJECT Name 	: WD Analytical Data Store Implementation 
Client		: Western Digital Inc, USA
Environment		:  DataStage, SQL Server, Netazza, UNIX, Hadoop, Apache ,HDFS,sqoop
Duration       	 	: May  2015- Nov 2015
Time Size      	 	 : 14
Role 		:   ETL and Big data Test lead
Project Description: WD ADS Implementation project involves transform its enterprise wide data warehousing, data movement and analytic technology environment and achieving the data from landing zone to  different dataset  using Hadoop file structure framework.  It involves developing an Enterprise Data warehouse solution and Analytics using HDFS on the Unix environment. The ADS project’s goal is to integrate data into two centralized repositories for the Media (MMO) and Head (MHO) divisions. It has two phase one is Data warehouse for Structure reports Analytics and Discovery of unstructured and semi structure   Media, graphics and voice data packet for big data Analytics.   
Role and Responsibilities:
As a ETL and Big data Test lead
Responsible for giving test approach for both Data Enterprise structure warehouse and big data Hbase.
Created test strategy with test approach, test plan, migration strategy and project plan documents by thorough understanding of the requirements, timelines and the budget.
Responsible for testing data movement between HDFS  and DB which is designed using sqoop. 
Preparing test case and test script based on the requirement.
Prepare Unix and Java script to test Mapping and business rule in landing to HDFS Discovery zone.
Responsible  for  testing WD products for their Thailand and Malaysia center. 
Written Test plans, Test cases (SQL Test script), executed Test cases for SQL/back-end test and tracked defects in Quality Centre based on the Business Requirements, Functional Requirements, Business Workflow's, Micro/Macro document. 
Performed System Integration System test (SIT), Conversion testing, Business Scenarios Testing UAT test and Production test per the needs of the application.
Prepared SQL test script for ADQ applied rule to Source extract landed correctly before applying ETL logic 
 Ensuring content and structure of all the testing artifacts are documented in Share Point Tool.
2) PROJECT NAME 	:  EDCOE -QA And   DATA Validation 
	
Client		: TIAA-CREF ,USA
Environment		:  DataStage, Teradata ,UNIX, OBIEE , Optim
Duration       	 	: June 2014- May 2015
Time Size      	 	 : 14
Domain 		:  Finance (Pensions Plan) 
Role 		:  ETL Test lead
Project Description:  TIAA CREF Enterprise Data Validation project involves transform its enterprise wide data warehousing, data movement and analytic technology environment. It involves developing an Enterprise Data warehouse solution using the IBM BDW (Bank Data Model) data model and IBM IIW anchoring through a phased consolidation of existing Data warehouse and Data Mart. The project is also to created and enhanced analytical and reporting capabilities for TIAA   Plan Customers   . 
Role and Responsibilities:
Responsible for leading a team in delivering all the testing activities. 
Assist Client project manager to define the project scope and schedule
Manage end to end testing work for the DW distribution portfolio and lead the project team of 15 members to assign module/activity/tasks/deliverables.
 Administrate project review, escalations, quality assurance, tasks’ completion, project deliverables, customer interface & project status reporting for the project
Design and document Data warehouse (EDW/RMW/ESP) and BI testing strategy covering the test cases for validating the data completeness and correctness, system performances of the ETL processes etc.
Developed high level test matrix based on business requirements, functional and technical specifications, and development standards for assigned projects/applications
Provide technical know-how, support, mentoring & coaching team members on technology, business & other project specific aspects
 Prepared QA Estimation, Test Approach, Test Plan and Test Strategy.
Prepared batch automated framework using Unix, SQL script for run all the test cases/test script for regression cycle.
Track and report upon testing activities, including the test case execution stage, defect status if any defects opened during execution and the testing results status and attained defect review meeting.
Maintained Traceability Matrix, Test Result, to track the requirements to the test cases to ensure complete test coverage in the Mercury Quality Center

3) PROJECT NAME 	: Data Transformation Implementation 
Client		: ITAU Unibanco, Brazil
Environment		:  DataStage, DB2 ,UNIX,   Cognos  
Test Data Management tool : Datastage, Optim 
Duration       	 	: September 2012-May 2014 
Time Size      	 	 :23
Domain 		:  Banking
Role 		: Test lead
Project Description:  ITAU Data Transformation Implementation   project involves transform its enterprise wide data warehousing, data movement and analytic technology environment. It involves developing an Enterprise Data warehouse solution using the IBM BDW (Bank Data Model) data model through a phased consolidation of existing Data warehouse and Data Mart. The project is also to create and enhance analytical and metadata capabilities for Itau Customers   . The Transformation is separated into the following two distinct efforts .Each running in parallel (Supply/Distribution) to the all releases. 
Role and Responsibilities:
Responsible for leading the team in delivering end to end ETL and BI Testing   to the  customer .
Responsible for daily and weekly calls with Customer/Geo based on the testing activities/progress.
Responsible for giving test approach for all the domains planned in   Itau DMT for all releases.
Prepared Test Strategy and Test Patten for all the cycles/releases.  
Assist Client project manager to define the project scope and schedule
Manage end to end testing work for the DW distribution portfolio and lead the project team of 23 members to assign module/activity/tasks/deliverables.
 Administrate project review, escalations, quality assurance, tasks’ completion, project deliverables, customer interface & project status reporting for the project
Written Test plans, Test cases (SQL Test script), executed Test cases for SQL/back-end test and tracked defects in Quality Centre based on the Business Requirements, Functional Requirements, Business Workflow's, Micro/Macro document and PCR documents.
Reviewed the Micro/Macro document and PCR Requirement with Architects, Database Developers and SME for better understanding of the requirements.
Performed System Integration System test (SIT), Conversion testing,   Business Scenarios Testing UAT test and Production test per the needs of the application.
Preparing SQL test script for all the test cases based on the requirement.
 Maintained Traceability Matrix, Test Result, to track the requirements to the test cases to ensure complete test coverage in the Mercury Quality Center.
SQL Test script writing as per Transformation rule as well as business rule  to validate data 
Track and report upon testing activities, including the test case execution stage, defect status if any defects opened during execution and the testing results status and attained defect review meeting
Prepared Test Result report/defect report   based on the Testing activities as well as daily test run.


4) Project Name :Markel Atlas R.1
Client		: Markel Insurance, USA
Environment		:  Informatica, Microsoft SQL, Teradata, Hp Quality Center ,Cognos 
Duration       	 	: Feb 2011-August 2012
Time Size      		 : 26
Domain 	      	     :  Insurance
Role 	       	     : Test lead

Project Description:  Markel Insurance Project is basically based on IBM IIW model Project .It involves developing an Enterprise Data warehouse solution using the IBM IIW (Insurance Data Model) data model through a phased consolidation of existing Data warehouse and Data Mart. Markel is embarking on a major realignment of its business from vertical ‘line-of-businesses’ to a new ‘Product and Region’ model across business lines under the Atlas Program. The Atlas Program will realize significant producer and operating benefits for Markel. The Data Warehouse initiative is part of the Atlas Program and is an 
enabler and primary vehicle for the systems alignment to the new business model. The main ambition of this project is to provide a common integrated data model with conformed values across ATLAS and Legacy systems to achieve an integrated enterprise view of submission, policy, reinsurance and claim data. Provides data and processes to support the new financial close process and accounting services
to improve efficiency and to support transition to Atlas applications.
Role and Responsibilities:
Responsible for leading a team in delivering all testing activities  to our customer .
Written Test plans, Test cases (SQL Test script), executed Test cases for SQL/back-end test and tracked defects in Quality Centre based on the Business Requirements, Functional Requirements, Business Workflow's, Micro/Macro document and PCR documents.
Reviewed the Micro/Macro document and PCR Requirement with Tech lead, Database Developers and Test team for better understanding of the requirements.
Performed System Integration System test (SIT), Conversion testing, Business Scenarios Testing UAT test and Production test per the needs of the application.
Prepared SQL test script for TDQ applied rule to Source extract landed correctly before applying ETL logic 
Ensuring content and structure of all the testing artifacts are documented in Share Point Tool.
Maintained Traceability Matrix, Test Result, to track the requirements to the test cases to ensure complete test coverage in the Mercury Quality Center.
Clearly communicated defects with developers and updated comments in Mercury Quality center.
Develops SQL  Test case/Test script and validate result Against success criteria
Keys are correctly generated and CDC has been correctly applied
SQL Test script writing as per Transformation rule as well as business rule  to validate data 
Track and report upon testing activities, including the test case execution stage, defect status if any defects opened during execution and the testing results status and attained defect review meeting
Preparing Test Result report based on the Testing activities as well as daily test run.


5) PROJECT NAME 	: IAF TRANSFORMATION
Client		: BANK OF AMERICA,USA
Environment		:  DataStage, Teradata, IBM AIX, Mainframe, Quality Center 9.2 
Duration       	 	: Nov 2009-Feb  2011
Time Size      	 	:8
Domain 		:  Banking
Role 		:  Customer and Card Test lead 
Project Description:  BANA Information and Analytics Foundation (IAF) project involves transform its enterprise wide data warehousing, data movement and analytic technology environment. It involves developing an Enterprise Data warehouse solution using the IBM BDW (Bank Data Model) data model through a phased consolidation of existing Data warehouse and Data Mart. The project is also expected to create and enhance analytical and metadata capabilities. The Transformation is separated into the following two distinct efforts .Each running in parallel (Supply/Distribution) to the all releases. 

Role and Responsibilities:
Written Test plans, Test cases (SQL Test script), executed Test cases for SQL/backend test and tracked defects in Quality Centre based on the Business Requirements, Functional Requirements, Business Workflows, Micro/Macro document and ICD documents.
Reviewed the Micro/Macro document and ICD Requirement with Tech lead, Database Developers and Test team for better understanding of the requirements.
Performed System Integration System test (SIT), regression testing, UAT test and Production test per the needs of the application.
Ensuring content and structure of all the testing artifacts are documented in Share Point Tool.
Maintained Traceability Matrix, Test Result, to track the requirements to the test cases to ensure complete test coverage in the Mercury Quality Center.
Clearly communicated defects with developers and updated comments in Mercury Quality center.
Develops and execute Test case/Test script and validate result Against success criteria
Keys are correctly generated and CDC has been correctly applied
Written SQL Test script as per Transformation rule to validate data 
Track and report upon testing activities, including the test case execution stage, defect status if any defects opened during execution and the testing results status and attained defect review meeting

 April 08 –  Sept 09, Senior Test Engineer      Javi Systems India Pvt Ltd, Bangalore 

Project Name 		: DiGi Mobile SIM Services (DSS)
Client			: DiGi Telecommunications Sdn. Bhd.Malasiya
Environment		:  DataStage, Teradata Sql, IBM AIX, Mainframe, Quality Center 9.2 
Telecom   Tools               :  Extreme Dialogue
Duration 			: May 2008 - September 2009
Time Size			: 20
	 Domain 		:  Telecom
	Role 			:  Senior Tester 

Description	: This telecom Application is designed to manage the billing objects Like SIM, PBX, PSTN, Customer etc. This project basically consist of lot of modules, Based of different modules currently handling SIM modules this is the most important module in telecom application.
		This SIM module is dedicated to manage SIM operation , promotions ,services , packages etc. SIM operation such as creation ,activation of SIM,SIM status change , Traff model change ,SIM Substitution, SIM Virtual Conversion .Operation on services such as service status change , service configuration etc. This module basically taken care of customer SIM activation to customer SIM deactivation.
Role and Responsibilities:
Understanding the requirement and Design document.
Doing walk through of Design document with onsite team for writing test script.
Created Test plan, Test Design, Test scripts and responsible for implementation of Test cases as Sql automated test scripts.
Writing SQL Test Script as per Transformation logic
Validating Mainframe data vs clean data using test script.
Validating the query according to the changes.
Involved in Writing Shell Scripting and Unix commands
Involved in writing Test cases and  SQL Test script peer review
Used Teradata tools to connect to Teradata Database to validate data that was populated by ETL applications using Teradata SQL Test scripts.
Executed backend data-driven test efforts with a focus on data transformations between various systems and a data warehouse.
Responsible for testing all new and existing ETL data warehouse components
Documentation, Defects tracking and retesting in Quality center
Performed Regression Testing after each build.
Performed Regression and SIT , Smoke Testing and Report generation for each and every Cycle


May 2006 –  April 2008, Software Engineer      CSC, Hyderabad 

Project Name 			:   ATT Consumer Billing Tool. 
Client				      :   AT&T, USA.
      	Environment			      :   C, Perl,  SQL Query,  Solaris, IBM Mainframe, Oracle 9i.
      	Duration                             	     :  May 2007 – April   2008
        Team Size                                             : 15
     Description                
This project basically used to generate the bills for consumer and corporate. This project basically consists of lot of modules .Based on different module I am handling three modules named as DFS, DPS and ESP. The main job of this applications to take the input invoice from mainframe and converts into text format and generate the bills in the PDF format as well as produce this bill into web for Customer Service  Rep. which is take care our our document generating system. 
Role & Responsibilities:
Understanding the requirement and Design document.
Involving in writing Shell Scripting, Perl script  and Unix command
Performed Functional, Integration, and System testing for different types of customer transactions.
Used SQL Queries to provide data manipulating in database
Defect tracking, maintenance and closure.
Monitoring Daily jobs, bills and log files.   
Resolved the production issues within SLA period.
Providing support and maintenance for the assigned module
Preparing the documents related the assigned module.
Tested the data extraction procedures designed to extract data into flat feed files
Providing support to production environment

Project Name                  :   ATT Consumer Billing Tool. 
Client			:   AT&T, USA.
      	Environment		:   C, Perl, Shell Script, SQL Query, UNIX, Solaris, IBM Mainframe, Oracle 9i.
      	Duration                             :  May 2007 – April   2008
        Team Size                           : 15
 Description : This project basically used to generate the bills for consumer and corporate. This project basically consists of lot of modules .Based on different module I am handling three modules named as DFS, DPS and ESP. The main job of this applications to take the input invoice from mainframe and converts into text format and generate the bills in the PDF format as well as produce this bill into web for Customer Service  Rep. which is take care our our document generating system. 
Role & Responsibilities:
Understanding the requirement and Design document.
Involving in writing Shell Scripting, Perl script  and Unix command
Performed Functional, Integration, and System testing for different types of customer transactions.
Used SQL Queries to provide data manipulating in database
Defect tracking, maintenance and closure.
Monitoring Daily jobs, bills and log files.   
Resolved the production issues within SLA period.
Providing support and maintenance for the assigned module
Preparing the documents related the assigned module.
Tested the data extraction procedures designed to extract data into flat feed files
Providing support to production environment

 Nov 2005- Aug 2006   Software Engineer   	Countrywide Financial Corporation, Mumbai

Project Name                  :   Interface with black Listed Customer (Countrywide home loan department). 
Client			:   Countrywide Financial Corp., USA
      	Environment		:   DataStage, Perl, Shell Script, Solaris, IBM Mainframe, Oracle 9i.
      	Duration                             :  Nov 2005 – Aug    2006
        Team Size                           : 10
     Description:
This Banking system is to provide and capture the details of the user and to maintain the detail information of the customers. The Registration module allows the new users to register themselves where as the login module allows the existing customers to log in to the systems. Account summary gives the details of the account information to the logged customers. All the transaction related details are captured in transaction module, which mostly include fund transfer, bill payment. It helps the customer to transfer funds and pay the bills to the third parties. Profile editing module helps to edit the customer’s own profile. Customer support module will be able to keep track of customer details and the holding relationship query.

    The responsibilities are as below  
Coding in Shell Script, Perl
Used SQL Query for data base issue
Performed Functional, Integration, and System testing for different types of customer transactions.
Tested the data extraction procedures designed to extract data into flat feed files Writing SQL Test Script.
Monitoring Pl\SQL Blocks
Performing Sanity Testing of applications
Monitoring Daily business processing activities
Providing support to production environment

 	 		

	

 
 

